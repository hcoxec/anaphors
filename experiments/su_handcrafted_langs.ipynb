{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from code.dataloader import DataHandler\n",
    "from string import ascii_lowercase, punctuation, digits, ascii_uppercas\n",
    "from typing import Any, Dict, Iterable, List, NamedTuple, Optional, Union\n",
    "import json\n",
    "import _jsonnet\n",
    "from code.analyser import Analyser as Scorer\n",
    "from code.agents import SenderInput, ReceiverOutput, RnnSenderReinforce, RnnReceiverDeterministic\n",
    "from code.game import ReinforceGame as Game\n",
    "from code.loss import ReconstructionLoss\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    '''\n",
    "    An object that makes a dictionary's keys attributes of the object, so they can\n",
    "    be called by subscripting (mimics the functionality of argparse)\n",
    "    '''\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "args = objectview(json.loads(_jsonnet.evaluate_file('learnability_config.jsonnet')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d3aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = DataHandler(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0569d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = args.signal_chars #for comp and null languages\n",
    "#vocab_size = args.signal_chars+2 #for tok language\n",
    "embedding_size = args.embedding_size\n",
    "hidden_size = args.hidden_size\n",
    "cell_type = args.rnn_cell\n",
    "signal_len = args.signal_len-1\n",
    "\n",
    "lr = args.learning_rate\n",
    "sender_entropy = args.sender_entropy\n",
    "gram_fn = args.gram_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"dicts/{gram_fn}_dict.json\") as infile:\n",
    "    grammar = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.comp_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanings = train[:][1]\n",
    "meanings = meanings.view(len(meanings), 5, 32)\n",
    "fmeanings = meanings.argmax(dim=-1)\n",
    "signals = train[:][0]\n",
    "messages = []\n",
    "for x in signals:\n",
    "    messages.append(x.tolist())\n",
    "smessages = [[j for j in x if j != 0] for x in messages]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adb78d8a",
   "metadata": {},
   "source": [
    "Get indices of redundant and non-redundant messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "redmeanings = []\n",
    "nonredmeanings = []\n",
    "redmessages = []\n",
    "nonredmessages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,x in enumerate(fmeanings):\n",
    "    if torch.equal(x[0], x[3]) or torch.equal(x[1], x[4]):\n",
    "        redmeanings.append(x)\n",
    "        redmessages.append(smessages[n])\n",
    "    else:\n",
    "        nonredmeanings.append(x)\n",
    "        nonredmessages.append(smessages[n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13f70231",
   "metadata": {},
   "source": [
    "Convert list of numbers to 'message string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a878e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allnos = [x for l in messages for x in l]\n",
    "charmapping = {n+1:a for n, a in enumerate(string.ascii_lowercase+string.ascii_uppercase)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "redcharmessages = []\n",
    "for m in redmessages:\n",
    "    newstr = \"\"\n",
    "    for mm in m:\n",
    "        c = charmapping[mm]\n",
    "        newstr += c\n",
    "    redcharmessages.append(newstr)\n",
    "nonredcharmessages = []\n",
    "for m in nonredmessages:\n",
    "    newstr = \"\"\n",
    "    for mm in m:\n",
    "        c = charmapping[mm]\n",
    "        newstr += c\n",
    "    nonredcharmessages.append(newstr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "882e5c41",
   "metadata": {},
   "source": [
    "Compute Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3270d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_stats(vocab):\n",
    "    pairs1 = {}\n",
    "    pairs2 = {}\n",
    "    pairs3 = {}\n",
    "    for word, frequency in vocab.items():\n",
    "        symbols = [char for char in word]\n",
    "        # count occurrences of pairs\n",
    "        for i in range(len(symbols)):   # unigrams\n",
    "            pair = (symbols[i])\n",
    "            current_frequency = pairs1.get(pair, 0)\n",
    "            pairs1[pair] = current_frequency + frequency\n",
    "        for i in range(len(symbols) - 1):   # bigrams\n",
    "            pair = (symbols[i], symbols[i + 1])\n",
    "            current_frequency = pairs2.get(pair, 0)\n",
    "            pairs2[pair] = current_frequency + frequency\n",
    "        for i in range(len(symbols) - 2):   # trigrams\n",
    "            pair = (symbols[i], symbols[i + 1], symbols[i + 2])\n",
    "            current_frequency = pairs3.get(pair, 0)\n",
    "            pairs3[pair] = current_frequency + frequency\n",
    "\n",
    "    pairs1_descending = OrderedDict(sorted(pairs1.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    pairs2_descending = OrderedDict(sorted(pairs2.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    pairs3_descending = OrderedDict(sorted(pairs3.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "    pairs1 = dict((''.join(k), v) for k,v in pairs1_descending.items())\n",
    "    pairs2 = dict((''.join(k), v) for k,v in pairs2_descending.items())\n",
    "    pairs3 = dict((''.join(k), v) for k,v in pairs3_descending.items())\n",
    "    \n",
    "    return pairs1, pairs2, pairs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonredict = {}\n",
    "redict = {}\n",
    "for entry in nonredcharmessages:\n",
    "    try:\n",
    "        nonredict[entry] += 1\n",
    "    except KeyError:\n",
    "        nonredict[entry] = 0\n",
    "        nonredict[entry] += 1\n",
    "\n",
    "for entry in redcharmessages:\n",
    "    try:\n",
    "        redict[entry] += 1\n",
    "    except KeyError:\n",
    "        redict[entry] = 0\n",
    "        redict[entry] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonredcharmessages1 = random.sample(nonredcharmessages, len(redcharmessages))\n",
    "othernonred = [x for x in nonredmessages if x not in nonredcharmessages1]\n",
    "nonredcharmessages2 = random.sample(nonredcharmessages, len(redcharmessages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd3da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonredict1 = {}\n",
    "nonredict2 = {}\n",
    "redict = {}\n",
    "for entry in nonredcharmessages1:\n",
    "    try:\n",
    "        nonredict1[entry] += 1\n",
    "    except KeyError:\n",
    "        nonredict1[entry] = 0\n",
    "        nonredict1[entry] += 1\n",
    "        \n",
    "for entry in nonredcharmessages2:\n",
    "    try:\n",
    "        nonredict2[entry] += 1\n",
    "    except KeyError:\n",
    "        nonredict2[entry] = 0\n",
    "        nonredict2[entry] += 1\n",
    "\n",
    "for entry in redcharmessages:\n",
    "    try:\n",
    "        redict[entry] += 1\n",
    "    except KeyError:\n",
    "        redict[entry] = 0\n",
    "        redict[entry] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdict1, rdict2, rdict3 = get_pair_stats(redict)\n",
    "odict1, odict2, odict3 = get_pair_stats(nonredict1)\n",
    "sdict1, sdict2, sdict3 = get_pair_stats(nonredict2)\n",
    "\n",
    "red_frequencies = {}\n",
    "red_frequencies['unigram'] = rdict1\n",
    "red_frequencies['bigram'] = rdict2\n",
    "red_frequencies['trigram'] = rdict3\n",
    "\n",
    "nonred_frequencies = {}\n",
    "nonred_frequencies['unigram'] = odict1\n",
    "nonred_frequencies['bigram'] = odict2\n",
    "nonred_frequencies['trigram'] = odict3\n",
    "\n",
    "samp_frequencies = {}\n",
    "samp_frequencies['unigram'] = sdict1\n",
    "samp_frequencies['bigram'] = sdict2\n",
    "samp_frequencies['trigram'] = sdict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_frequencies['bigram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1395e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #JACCARDS\n",
    "sorted_reds_unis = sorted(red_frequencies['unigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_other_unis = sorted(nonred_frequencies['unigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_samps_unis = sorted(samp_frequencies['unigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "sorted_reds_unis = sorted_reds_unis[:100]\n",
    "sorted_reds_unis = [k[0] for k in sorted_reds_unis]\n",
    "sorted_other_unis = sorted_other_unis[:100]\n",
    "sorted_other_unis = [k[0] for k in sorted_other_unis]\n",
    "sorted_samps_unis = sorted_samps_unis[:100]\n",
    "sorted_samps_unis = [k[0] for k in sorted_samps_unis]\n",
    "uni_and_jaccard = jaccard_similarity(sorted_samps_unis, sorted_reds_unis)\n",
    "uni_nonred_jaccard = jaccard_similarity(sorted_samps_unis, sorted_other_unis)\n",
    "\n",
    "sorted_reds_bis = sorted(red_frequencies['bigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_other_bis = sorted(nonred_frequencies['bigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_samps_bis = sorted(samp_frequencies['bigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "sorted_reds_bis = sorted_reds_bis[:100]\n",
    "sorted_reds_bis = [k[0] for k in sorted_reds_bis]\n",
    "sorted_other_bis = sorted_other_bis[:100]\n",
    "sorted_other_bis = [k[0] for k in sorted_other_bis]\n",
    "sorted_samps_bis = sorted_samps_bis[:100]\n",
    "sorted_samps_bis = [k[0] for k in sorted_samps_bis]\n",
    "bi_and_jaccard = jaccard_similarity(sorted_samps_bis, sorted_reds_bis)\n",
    "bi_nonred_jaccard = jaccard_similarity(sorted_samps_bis, sorted_other_bis)\n",
    "\n",
    "sorted_reds_tris = sorted(red_frequencies['trigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_other_tris = sorted(nonred_frequencies['trigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_samps_tris = sorted(samp_frequencies['trigram'].items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "sorted_reds_tris = sorted_reds_tris[:100]\n",
    "sorted_reds_tris = [k[0] for k in sorted_reds_tris]\n",
    "sorted_other_tris = sorted_other_tris[:100]\n",
    "sorted_other_tris = [k[0] for k in sorted_other_tris]\n",
    "sorted_samps_tris = sorted_samps_tris[:100]\n",
    "sorted_samps_tris = [k[0] for k in sorted_samps_tris]\n",
    "tri_and_jaccard = jaccard_similarity(sorted_other_tris, sorted_reds_tris)\n",
    "tri_nonred_jaccard = jaccard_similarity(sorted_samps_tris, sorted_other_tris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25480d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_and_jaccard, uni_nonred_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79544d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bi_and_jaccard, bi_nonred_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tri_and_jaccard, tri_nonred_jaccard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
